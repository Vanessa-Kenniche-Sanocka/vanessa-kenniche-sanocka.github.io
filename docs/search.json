[
  {
    "objectID": "index.pl.html",
    "href": "index.pl.html",
    "title": "",
    "section": "",
    "text": "KENSAN.VAN@GMAIL.COM\n+33 7 68 14 01 74\nLinkedIn\n\n\n\n Zaawansowana ekonometria, analiza przyczynowości, uczenie maszynowe, NLP, analityka geospatial, inżynieria danych, wizualizacja interaktywna, ewaluacja polityk publicznych, dane poufne \n\n\n\n Python, R, SQL, JavaScript, HTML/CSS, Bash \n\n\n\n Spark, Airflow, ElasticSearch, PyTorch, TensorFlow, Quarto, Power BI, Shiny, Git/GitLab, Docker, QGIS, CASD \n\n\n\nFrancuski natywny\nPolski natywny\nAngielski C1 (TOEIC)\n\n\n\n\n\n\n\n\n\n Vanessa Kenniche Sanocka, Inżynier Data Science\nData scientist w Francuskiej Izbie Obrachunkowej od 2023\nAbsolwentka Programu Magisterskiego Inżynierskiego (CMI) Data Science for Social Sciences, Uniwersytet Paris Nanterre\nSpecjalizacja w ekonomii ilościowej i analizie polityk publicznych. Doświadczenie w kierowaniu projektami od początku do końca: modelowanie ekonometryczne, przetwarzanie dużych i wrażliwych zbiorów danych, przekształcanie złożonych analiz w dostępne rekomendacje dla interesariuszy. Doświadczenie międzynarodowe i umiejętność prezentacji przed różnorodnymi audytoriami, od sędziów po zespoły techniczne. Ustrukturyzowane podejście zorientowane na reprodukowalność, transfer wiedzy i wpływ na decyzje. \n\n Pobierz CV Vanessa KENNICHE SANOCKA \n\n\n\n\n\n\n\n Praca przy projektach ewaluacji polityk publicznych w ramach jurysdykcji finansowych. Produkcja analiz zorientowanych na decyzje we współpracy bezpośredniej z sędziami i interesariuszami instytucjonalnymi. Znajomość standardów poufności i jasna komunikacja w kontekstach formalnych. \n\n\nHarmonizacja heterogenicznych danych GIS Francja-Szwajcaria w celu identyfikacji transgranicznych nieciągłości regulacyjnych. Badania i wykorzystanie oficjalnych baz danych (IGN, SwissTopo, SITG), łączenie nomenklatur i harmonizacja skal terytorialnych. Przekształcanie złożonych analiz geospatial w interaktywne wizualizacje i rekomendacje polityk publicznych dla zespołów instytucjonalnych.\nPython QGIS GeoPandas PlotLy\n\n\n\nZaawansowane modelowanie ekonometryczne na danych krajowych (GART, CEREMA) łączące modele panelowe, event studies i metody badawcze. Przetwarzanie poufnych baz danych użytkowników poprzez próbkowanie stratyfikowane, dostosowanie propensity score, kalibrację marż i bootstrapping. Wzbogacenie przez badania uzupełniające (baza FILOSOFI) w celu sformułowania rekomendacji taryfikacyjnych z interaktywną prezentacją poprzez Shiny.\nR Panel Data Event Study Causal Inference Survey Methods Propensity Score Bootstrap Shiny Leaflet\n\n\n\nPełna integracja do eksploracji i semantycznego przeszukiwania dokumentów instytucjonalnych. Kompletna architektura obejmująca preprocessing NLP (tokenizacja, lematyzacja, NER), modele embeddings (SBERT, Word2Vec), indeksowanie ElasticSearch i interfejs webowy Next.js. Rozwój FastAPI dla zapytań w czasie rzeczywistym i migracja do nowego wewnętrznego systemu archiwizacji.\nPython spaCy SBERT ElasticSearch RAG FastAPI Next.js NLP Embeddings\n\n\n\nAlgorytmy uczenia maszynowego na danych longitudinalnych z Krajowego Rejestru Karnego. Analiza przeżycia i scoring ryzyka dla trajektorii przestępczych. Intensywne przetwarzanie identyfikatorów, konstrukcja paneli czasowych i modelowanie recydywy do wsparcia decyzji publicznych w środowisku zabezpieczonym wysokiej poufności.\nR Machine Learning Survival Analysis Panel Data Risk Scoring CASD Longitudinal Data\n\n\n\nWykorzystanie badań zatrudnienia INSEE i baz podatkowych poprzez CASD do ewaluacji reform (emerytury, ustawa PACTE). Modelowanie statystyczne na sprzężonych danych administracyjnych, harmonizacja heterogenicznych baz danych i dopasowywanie identyfikatorów. Produkcja wskaźników ekonomicznych i ewaluacja wpływu polityk społecznych.\nR Statistical Modeling Administrative Data Policy Evaluation Data Linkage CASD Economic Indicators\n\n\n\n\n\n\nProjektowanie narzędzi edukacyjnych: moduł badań statystycznych (stratyfikacja, ważenie, kalibracja), tutorial kartografii interaktywnej (R/Python, Leaflet/Folium), standardowy szablon Quarto dla raportów reprodukowalnych. Prowadzenie warsztatów wewnętrznych i dokumentacja techniczna dla zbiorowego rozwoju umiejętności.\nR Python Quarto Pedagogy Documentation\n\n\n\nArchitektura dzielenia się wiedzą: rozwój wewnętrznej platformy do centralizacji zasobów, peer reviews i sesji szkoleniowych. Implementacja dobrych praktyk Git, standardów kodu i procesów walidacji współpracy.\nGitLab Collaboration Knowledge Management\n\n\n\n\n\n\n\n\n Selektywny i intensywny program strukturalny wokół projektów wieloletnich. Wzmocnione kursy w ekonometrii, data science i analizie polityk publicznych. Ukończenie dwóch prac badawczych pod nadzorem Patrice Bertail, łączących zaawansowane modelowanie i wartościowanie naukowe. Podejście projektowe z autonomią w identyfikacji źródeł danych i zastosowaniu w rzeczywistości. \n\n\nModelowanie nadzorowane na danych niezrównoważonych. Zastosowanie technik SMOTE/B-SMOTE, walidacja krzyżowa i scoring ryzyka finansowego. Porównanie modeli (Random Forest, XGBoost, SVM) z optymalizacją metryk dla klas mniejszościowych.\nPython Scikit-learn SMOTE Cross-validation Financial Risk\n\n\n\nScraping wysokiej częstotliwości do data lake, klasyfikacja i estymacja dostosowań cen poprzez modele fixed-effects. Testy robustności i wykrywanie wzorców automatycznej taryfikacji na danych e-commerce.\nPython Web Scraping Fixed Effects Price Analytics Data Lake\n\n\n\nModelowanie ekonometryczne cross-country (logit/Poisson) na danych badawczych. Testy robustności poprzez regularyzację Lasso i analiza porównawcza czynników innowacji (Indie, Bangladesz, Pakistan, Nepal).\nR Econometrics Cross-country Analysis Lasso Regularization Innovation Policy\n\n\n\nScraping otwartych danych rządowych, konstrukcja macierzy odległości Manhattan i clustering spring layout do identyfikacji koalicji transpartyjnych. Interaktywna wizualizacja bliskości politycznych.\nPython NetworkX Graph Theory Political Analysis Dash\n\n\n\nHurtownia danych MySQL schema gwiazdy, zapytania okienkowe (średnie kroczące) i dashboard terytorialny dla wskaźników polityki mieszkaniowej. Kompletna architektura BI z ETL poprzez MageAI.\nSQL MySQL Power BI Data Warehouse ETL\n\n\n\nMapowanie konkurencyjne i pozycjonowanie strategiczne sektorowe z wizualizacjami geospatial. Analiza rodzin patentów, cytowań i rekomendacje polityki przemysłowej na oficjalnej bazie danych.\nPython SQL PATSTAT Patent Analysis Geospatial Viz\n\n\n\nPipeline zbierania i analizy: masowy scraping danych, orkiestracja Airflow, ingestion w czasie rzeczywistym do data lake. Architektura Kafka/Spark z magazynowaniem Parquet i monitoringiem Grafana.\nPython Airflow Kafka Spark Data Lake\n\n\n\nKonstrukcja grafu bipartite aktorzy-filmy, obliczanie najkrótszych ścieżek z NetworkX. Interfejs Dash dla interaktywnych zapytań z ograniczeniami czasowymi i wizualizacją sieci.\nPython NetworkX Graph Algorithms Dash Interactive Viz\n\n\n\n\n\n\n\n\nSensibilizacja uczennic liceum na kariery naukowe w ramach narodowego planu promocji kierunków STEM. Interwencja na Uniwersytecie Paris Nanterre dla dekonstrukcji stereotypów płciowych w matematyce i naukach.\n\n\n\nRozwój zasobów edukacyjnych: szablony Quarto, moduły R dla metod badawczych, tutoriale kartografii interaktywnej. Dzielenie się najlepszymi praktykami w reprodukowalności i dokumentacji technicznej.\n\n\n\nSztuka cyfrowa, projektowanie graficzne, modelowanie 3D, kolarstwo górskie, gimnastyka, historia współczesna, numizmatyka"
  },
  {
    "objectID": "index.pl.html#francuska-izba-obrachunkowa-inżynier-data-science-2023-obecnie",
    "href": "index.pl.html#francuska-izba-obrachunkowa-inżynier-data-science-2023-obecnie",
    "title": "",
    "section": "",
    "text": "Praca przy projektach ewaluacji polityk publicznych w ramach jurysdykcji finansowych. Produkcja analiz zorientowanych na decyzje we współpracy bezpośredniej z sędziami i interesariuszami instytucjonalnymi. Znajomość standardów poufności i jasna komunikacja w kontekstach formalnych. \n\n\nHarmonizacja heterogenicznych danych GIS Francja-Szwajcaria w celu identyfikacji transgranicznych nieciągłości regulacyjnych. Badania i wykorzystanie oficjalnych baz danych (IGN, SwissTopo, SITG), łączenie nomenklatur i harmonizacja skal terytorialnych. Przekształcanie złożonych analiz geospatial w interaktywne wizualizacje i rekomendacje polityk publicznych dla zespołów instytucjonalnych.\nPython QGIS GeoPandas PlotLy\n\n\n\nZaawansowane modelowanie ekonometryczne na danych krajowych (GART, CEREMA) łączące modele panelowe, event studies i metody badawcze. Przetwarzanie poufnych baz danych użytkowników poprzez próbkowanie stratyfikowane, dostosowanie propensity score, kalibrację marż i bootstrapping. Wzbogacenie przez badania uzupełniające (baza FILOSOFI) w celu sformułowania rekomendacji taryfikacyjnych z interaktywną prezentacją poprzez Shiny.\nR Panel Data Event Study Causal Inference Survey Methods Propensity Score Bootstrap Shiny Leaflet\n\n\n\nPełna integracja do eksploracji i semantycznego przeszukiwania dokumentów instytucjonalnych. Kompletna architektura obejmująca preprocessing NLP (tokenizacja, lematyzacja, NER), modele embeddings (SBERT, Word2Vec), indeksowanie ElasticSearch i interfejs webowy Next.js. Rozwój FastAPI dla zapytań w czasie rzeczywistym i migracja do nowego wewnętrznego systemu archiwizacji.\nPython spaCy SBERT ElasticSearch RAG FastAPI Next.js NLP Embeddings\n\n\n\nAlgorytmy uczenia maszynowego na danych longitudinalnych z Krajowego Rejestru Karnego. Analiza przeżycia i scoring ryzyka dla trajektorii przestępczych. Intensywne przetwarzanie identyfikatorów, konstrukcja paneli czasowych i modelowanie recydywy do wsparcia decyzji publicznych w środowisku zabezpieczonym wysokiej poufności.\nR Machine Learning Survival Analysis Panel Data Risk Scoring CASD Longitudinal Data\n\n\n\nWykorzystanie badań zatrudnienia INSEE i baz podatkowych poprzez CASD do ewaluacji reform (emerytury, ustawa PACTE). Modelowanie statystyczne na sprzężonych danych administracyjnych, harmonizacja heterogenicznych baz danych i dopasowywanie identyfikatorów. Produkcja wskaźników ekonomicznych i ewaluacja wpływu polityk społecznych.\nR Statistical Modeling Administrative Data Policy Evaluation Data Linkage CASD Economic Indicators"
  },
  {
    "objectID": "index.pl.html#projekty-przekrojowe-i-wkład-instytucjonalny",
    "href": "index.pl.html#projekty-przekrojowe-i-wkład-instytucjonalny",
    "title": "",
    "section": "",
    "text": "Projektowanie narzędzi edukacyjnych: moduł badań statystycznych (stratyfikacja, ważenie, kalibracja), tutorial kartografii interaktywnej (R/Python, Leaflet/Folium), standardowy szablon Quarto dla raportów reprodukowalnych. Prowadzenie warsztatów wewnętrznych i dokumentacja techniczna dla zbiorowego rozwoju umiejętności.\nR Python Quarto Pedagogy Documentation\n\n\n\nArchitektura dzielenia się wiedzą: rozwój wewnętrznej platformy do centralizacji zasobów, peer reviews i sesji szkoleniowych. Implementacja dobrych praktyk Git, standardów kodu i procesów walidacji współpracy.\nGitLab Collaboration Knowledge Management"
  },
  {
    "objectID": "index.pl.html#program-magisterski-inżynierski-data-science-for-social-sciences-uniwersytet-paris-nanterre-2020-2025",
    "href": "index.pl.html#program-magisterski-inżynierski-data-science-for-social-sciences-uniwersytet-paris-nanterre-2020-2025",
    "title": "",
    "section": "",
    "text": "Selektywny i intensywny program strukturalny wokół projektów wieloletnich. Wzmocnione kursy w ekonometrii, data science i analizie polityk publicznych. Ukończenie dwóch prac badawczych pod nadzorem Patrice Bertail, łączących zaawansowane modelowanie i wartościowanie naukowe. Podejście projektowe z autonomią w identyfikacji źródeł danych i zastosowaniu w rzeczywistości. \n\n\nModelowanie nadzorowane na danych niezrównoważonych. Zastosowanie technik SMOTE/B-SMOTE, walidacja krzyżowa i scoring ryzyka finansowego. Porównanie modeli (Random Forest, XGBoost, SVM) z optymalizacją metryk dla klas mniejszościowych.\nPython Scikit-learn SMOTE Cross-validation Financial Risk\n\n\n\nScraping wysokiej częstotliwości do data lake, klasyfikacja i estymacja dostosowań cen poprzez modele fixed-effects. Testy robustności i wykrywanie wzorców automatycznej taryfikacji na danych e-commerce.\nPython Web Scraping Fixed Effects Price Analytics Data Lake\n\n\n\nModelowanie ekonometryczne cross-country (logit/Poisson) na danych badawczych. Testy robustności poprzez regularyzację Lasso i analiza porównawcza czynników innowacji (Indie, Bangladesz, Pakistan, Nepal).\nR Econometrics Cross-country Analysis Lasso Regularization Innovation Policy\n\n\n\nScraping otwartych danych rządowych, konstrukcja macierzy odległości Manhattan i clustering spring layout do identyfikacji koalicji transpartyjnych. Interaktywna wizualizacja bliskości politycznych.\nPython NetworkX Graph Theory Political Analysis Dash\n\n\n\nHurtownia danych MySQL schema gwiazdy, zapytania okienkowe (średnie kroczące) i dashboard terytorialny dla wskaźników polityki mieszkaniowej. Kompletna architektura BI z ETL poprzez MageAI.\nSQL MySQL Power BI Data Warehouse ETL\n\n\n\nMapowanie konkurencyjne i pozycjonowanie strategiczne sektorowe z wizualizacjami geospatial. Analiza rodzin patentów, cytowań i rekomendacje polityki przemysłowej na oficjalnej bazie danych.\nPython SQL PATSTAT Patent Analysis Geospatial Viz\n\n\n\nPipeline zbierania i analizy: masowy scraping danych, orkiestracja Airflow, ingestion w czasie rzeczywistym do data lake. Architektura Kafka/Spark z magazynowaniem Parquet i monitoringiem Grafana.\nPython Airflow Kafka Spark Data Lake\n\n\n\nKonstrukcja grafu bipartite aktorzy-filmy, obliczanie najkrótszych ścieżek z NetworkX. Interfejs Dash dla interaktywnych zapytań z ograniczeniami czasowymi i wizualizacją sieci.\nPython NetworkX Graph Algorithms Dash Interactive Viz"
  },
  {
    "objectID": "index.en.html",
    "href": "index.en.html",
    "title": "",
    "section": "",
    "text": "KENSAN.VAN@GMAIL.COM\n+33 7 68 14 01 74\nLinkedIn\n\n\n\n Advanced econometrics, causal analysis, machine learning, NLP, geospatial analytics, data engineering, interactive visualization, public policy evaluation, confidential data \n\n\n\n Python, R, SQL, JavaScript, HTML/CSS, Bash \n\n\n\n Spark, Airflow, ElasticSearch, PyTorch, TensorFlow, Quarto, Power BI, Shiny, Git/GitLab, Docker, QGIS, CASD \n\n\n\nNative French\nNative Polish\nEnglish C1 (TOEIC)\n\n\n\n\n\n\n\n\n\n Vanessa Kenniche Sanocka, Data Science Engineer\nData scientist at the French Court of Audit since 2023\nGraduate of the Engineering Master’s Program (CMI) Data Science for Social Sciences, University of Paris Nanterre\nSpecialized in quantitative economics and public policy analysis. Expertise in end-to-end project leadership: econometric modeling, large-scale and sensitive data processing, transforming complex analyses into accessible recommendations for stakeholders. International experience and ability to present to diverse audiences, from magistrates to technical teams. Structured approach focused on reproducibility, knowledge transfer and decision impact. \n\n Download Vanessa KENNICHE SANOCKA’s CV \n\n\n\n\n\n\n\n Intervention on public policy evaluation projects within financial jurisdictions. Production of decision-oriented analyses in direct collaboration with magistrates and institutional stakeholders. Mastery of confidentiality standards and clear communication in formal contexts. \n\n\nHarmonization of heterogeneous GIS data France-Switzerland to identify cross-border regulatory discontinuities. Research and exploitation of official databases (IGN, SwissTopo, SITG), coupling of nomenclatures and harmonization of territorial scales. Transformation of complex geospatial analyses into interactive visualizations and public policy recommendations for institutional teams.\nPython QGIS GeoPandas PlotLy\n\n\n\nAdvanced econometric modeling on national data (GART, CEREMA) combining panel models, event studies and survey methods. Processing of confidential user databases through stratified sampling, propensity score adjustment, margin calibration and bootstrapping. Enhancement through complementary research (FILOSOFI database) to formulate pricing recommendations with interactive delivery via Shiny.\nR Panel Data Event Study Causal Inference Survey Methods Propensity Score Bootstrap Shiny Leaflet\n\n\n\nFull-stack integration for exploration and semantic querying of institutional documents. Complete architecture including NLP preprocessing (tokenization, lemmatization, NER), embedding models (SBERT, Word2Vec), ElasticSearch indexing and Next.js web interface. FastAPI development for real-time queries and migration to new internal archiving system.\nPython spaCy SBERT ElasticSearch RAG FastAPI Next.js NLP Embeddings\n\n\n\nMachine learning algorithms on longitudinal data from the National Criminal Record. Survival analysis and risk scoring for criminal trajectories. Intensive processing of identifiers, temporal panel construction and recidivism modeling for public decision support in high-confidentiality secure environment.\nR Machine Learning Survival Analysis Panel Data Risk Scoring CASD Longitudinal Data\n\n\n\nExploitation of INSEE employment surveys and tax databases via CASD for reform evaluation (pensions, PACTE law). Statistical modeling on coupled administrative data, harmonization of heterogeneous databases and identifier matching. Production of economic indicators and impact evaluation of social policies.\nR Statistical Modeling Administrative Data Policy Evaluation Data Linkage CASD Economic Indicators\n\n\n\n\n\n\nDesign of educational tools: statistical survey module (stratification, weighting, calibration), interactive cartography tutorial (R/Python, Leaflet/Folium), standardized Quarto template for reproducible reports. Internal workshop facilitation and technical documentation for collective skill development.\nR Python Quarto Pedagogy Documentation\n\n\n\nKnowledge sharing architecture: development of an internal platform for resource centralization, peer reviews and training sessions. Implementation of Git best practices, code standards and collaborative validation processes.\nGitLab Collaboration Knowledge Management\n\n\n\n\n\n\n\n\n Selective and intensive program structured around multi-year projects. Reinforced courses in econometrics, data science and public policy analysis. Completion of two research theses under supervision of Patrice Bertail, combining advanced modeling and scientific valorization. Project-based approach with autonomy in identifying data sources and real-world application. \n\n\nSupervised modeling on imbalanced data. Application of SMOTE/B-SMOTE techniques, cross-validation and financial risk scoring. Model comparison (Random Forest, XGBoost, SVM) with metric optimization for minority classes.\nPython Scikit-learn SMOTE Cross-validation Financial Risk\n\n\n\nHigh-frequency scraping to data lake, classification and estimation of price adjustments through fixed-effects models. Robustness testing and detection of automated pricing patterns on e-commerce data.\nPython Web Scraping Fixed Effects Price Analytics Data Lake\n\n\n\nCross-country econometric modeling (logit/Poisson) on survey data. Robustness testing through Lasso regularization and comparative analysis of innovation factors (India, Bangladesh, Pakistan, Nepal).\nR Econometrics Cross-country Analysis Lasso Regularization Innovation Policy\n\n\n\nGovernment open data scraping, Manhattan distance matrix construction and spring layout clustering to identify cross-party coalitions. Interactive visualization of political proximities.\nPython NetworkX Graph Theory Political Analysis Dash\n\n\n\nMySQL star schema data warehouse, windowing queries (moving averages) and territorial dashboard for housing policy indicators. Complete BI architecture with ETL via MageAI.\nSQL MySQL Power BI Data Warehouse ETL\n\n\n\nCompetitive mapping and sectoral strategic positioning with geospatial visualizations. Patent family analysis, citations and industrial policy recommendations on official database.\nPython SQL PATSTAT Patent Analysis Geospatial Viz\n\n\n\nCollection and analysis pipeline: massive data scraping, Airflow orchestration, real-time ingestion into data lake. Kafka/Spark architecture with Parquet storage and Grafana monitoring.\nPython Airflow Kafka Spark Data Lake\n\n\n\nBipartite graph construction actors-films, shortest path calculation with NetworkX. Dash interface for interactive queries with temporal constraints and network visualization.\nPython NetworkX Graph Algorithms Dash Interactive Viz\n\n\n\n\n\n\n\n\nHigh school student outreach to scientific careers as part of the national STEM promotion plan. Intervention at University of Paris Nanterre for deconstruction of gender stereotypes in mathematics and sciences.\n\n\n\nEducational resource development: Quarto templates, R modules for survey methods, interactive cartography tutorials. Sharing best practices in reproducibility and technical documentation.\n\n\n\nDigital arts, graphic design, 3D modeling, mountain biking, gymnastics, contemporary history, numismatics"
  },
  {
    "objectID": "index.en.html#french-court-of-audit-data-science-engineer-2023-present",
    "href": "index.en.html#french-court-of-audit-data-science-engineer-2023-present",
    "title": "",
    "section": "",
    "text": "Intervention on public policy evaluation projects within financial jurisdictions. Production of decision-oriented analyses in direct collaboration with magistrates and institutional stakeholders. Mastery of confidentiality standards and clear communication in formal contexts. \n\n\nHarmonization of heterogeneous GIS data France-Switzerland to identify cross-border regulatory discontinuities. Research and exploitation of official databases (IGN, SwissTopo, SITG), coupling of nomenclatures and harmonization of territorial scales. Transformation of complex geospatial analyses into interactive visualizations and public policy recommendations for institutional teams.\nPython QGIS GeoPandas PlotLy\n\n\n\nAdvanced econometric modeling on national data (GART, CEREMA) combining panel models, event studies and survey methods. Processing of confidential user databases through stratified sampling, propensity score adjustment, margin calibration and bootstrapping. Enhancement through complementary research (FILOSOFI database) to formulate pricing recommendations with interactive delivery via Shiny.\nR Panel Data Event Study Causal Inference Survey Methods Propensity Score Bootstrap Shiny Leaflet\n\n\n\nFull-stack integration for exploration and semantic querying of institutional documents. Complete architecture including NLP preprocessing (tokenization, lemmatization, NER), embedding models (SBERT, Word2Vec), ElasticSearch indexing and Next.js web interface. FastAPI development for real-time queries and migration to new internal archiving system.\nPython spaCy SBERT ElasticSearch RAG FastAPI Next.js NLP Embeddings\n\n\n\nMachine learning algorithms on longitudinal data from the National Criminal Record. Survival analysis and risk scoring for criminal trajectories. Intensive processing of identifiers, temporal panel construction and recidivism modeling for public decision support in high-confidentiality secure environment.\nR Machine Learning Survival Analysis Panel Data Risk Scoring CASD Longitudinal Data\n\n\n\nExploitation of INSEE employment surveys and tax databases via CASD for reform evaluation (pensions, PACTE law). Statistical modeling on coupled administrative data, harmonization of heterogeneous databases and identifier matching. Production of economic indicators and impact evaluation of social policies.\nR Statistical Modeling Administrative Data Policy Evaluation Data Linkage CASD Economic Indicators"
  },
  {
    "objectID": "index.en.html#cross-cutting-projects-and-institutional-contributions",
    "href": "index.en.html#cross-cutting-projects-and-institutional-contributions",
    "title": "",
    "section": "",
    "text": "Design of educational tools: statistical survey module (stratification, weighting, calibration), interactive cartography tutorial (R/Python, Leaflet/Folium), standardized Quarto template for reproducible reports. Internal workshop facilitation and technical documentation for collective skill development.\nR Python Quarto Pedagogy Documentation\n\n\n\nKnowledge sharing architecture: development of an internal platform for resource centralization, peer reviews and training sessions. Implementation of Git best practices, code standards and collaborative validation processes.\nGitLab Collaboration Knowledge Management"
  },
  {
    "objectID": "index.en.html#engineering-masters-program-data-science-for-social-sciences-university-of-paris-nanterre-2020-2025",
    "href": "index.en.html#engineering-masters-program-data-science-for-social-sciences-university-of-paris-nanterre-2020-2025",
    "title": "",
    "section": "",
    "text": "Selective and intensive program structured around multi-year projects. Reinforced courses in econometrics, data science and public policy analysis. Completion of two research theses under supervision of Patrice Bertail, combining advanced modeling and scientific valorization. Project-based approach with autonomy in identifying data sources and real-world application. \n\n\nSupervised modeling on imbalanced data. Application of SMOTE/B-SMOTE techniques, cross-validation and financial risk scoring. Model comparison (Random Forest, XGBoost, SVM) with metric optimization for minority classes.\nPython Scikit-learn SMOTE Cross-validation Financial Risk\n\n\n\nHigh-frequency scraping to data lake, classification and estimation of price adjustments through fixed-effects models. Robustness testing and detection of automated pricing patterns on e-commerce data.\nPython Web Scraping Fixed Effects Price Analytics Data Lake\n\n\n\nCross-country econometric modeling (logit/Poisson) on survey data. Robustness testing through Lasso regularization and comparative analysis of innovation factors (India, Bangladesh, Pakistan, Nepal).\nR Econometrics Cross-country Analysis Lasso Regularization Innovation Policy\n\n\n\nGovernment open data scraping, Manhattan distance matrix construction and spring layout clustering to identify cross-party coalitions. Interactive visualization of political proximities.\nPython NetworkX Graph Theory Political Analysis Dash\n\n\n\nMySQL star schema data warehouse, windowing queries (moving averages) and territorial dashboard for housing policy indicators. Complete BI architecture with ETL via MageAI.\nSQL MySQL Power BI Data Warehouse ETL\n\n\n\nCompetitive mapping and sectoral strategic positioning with geospatial visualizations. Patent family analysis, citations and industrial policy recommendations on official database.\nPython SQL PATSTAT Patent Analysis Geospatial Viz\n\n\n\nCollection and analysis pipeline: massive data scraping, Airflow orchestration, real-time ingestion into data lake. Kafka/Spark architecture with Parquet storage and Grafana monitoring.\nPython Airflow Kafka Spark Data Lake\n\n\n\nBipartite graph construction actors-films, shortest path calculation with NetworkX. Dash interface for interactive queries with temporal constraints and network visualization.\nPython NetworkX Graph Algorithms Dash Interactive Viz"
  },
  {
    "objectID": "index.fr.html",
    "href": "index.fr.html",
    "title": "",
    "section": "",
    "text": "KENSAN.VAN@GMAIL.COM\n+33 7 68 14 01 74\nLinkedIn\n\n\n\n Économétrie avancée, analyse causale, machine learning, NLP, géospatial analytics, data engineering, visualisation interactive, évaluation de politiques publiques, données confidentielles \n\n\n\n Python, R, SQL, JavaScript, HTML/CSS, Bash \n\n\n\n Spark, Airflow, ElasticSearch, PyTorch, TensorFlow, Quarto, Power BI, Shiny, Git/GitLab, Docker, QGIS, CASD \n\n\n\nFrançais natif\nPolonais natif\nAnglais C1 (TOEIC)\n\n\n\n\n\n\n\n\n\n Vanessa Kenniche Sanocka, Data Science Engineer\nData scientist à la Cour des comptes depuis 2023\nDiplômée du Cursus Master Ingénierie (CMI) Data Science for Social Sciences, Université Paris Nanterre\nSpécialisée en économie quantitative et analyse de politiques publiques. Expertise en conduite de projets de bout en bout : modélisation économétrique, traitement de données volumineuses et sensibles, transformation d’analyses complexes en recommandations accessibles aux parties prenantes. Expérience internationale et capacité à présenter devant des publics variés, de magistrats aux équipes techniques. Approche structurée orientée reproductibilité, transmission et impact décisionnel. \n\n Télécharger le CV de Vanessa KENNICHE SANOCKA \n\n\n\n\n\n\n\n Intervention sur des projets d’évaluation de politiques publiques au sein de juridictions financières. Production d’analyses orientées décision en collaboration directe avec magistrats et parties prenantes institutionnelles. Maîtrise des standards de confidentialité et restitution claire dans des contextes formels. \n\n\nHarmonisation de données SIG hétérogènes France-Suisse pour identifier les discontinuités réglementaires transfrontalières. Recherche et exploitation de bases officielles (IGN, SwissTopo, SITG), couplage de nomenclatures et harmonisation d’échelles territoriales. Transformation d’analyses géospatiales complexes en visualisations interactives et recommandations de politique publique pour équipes institutionnelles.\nPython QGIS GeoPandas PlotLy\n\n\n\nModélisation économétrique avancée sur données nationales (GART, CEREMA) combinant panel models, event studies et méthodes de sondage. Traitement de bases confidentielles d’usagers par échantillonnage stratifié, redressement par score de propension, calage sur marges et bootstrapping. Enrichissement par recherche complémentaire (base FILOSOFI) pour formuler des recommandations tarifaires avec restitution interactive via Shiny.\nR Panel Data Event Study Causal Inference Survey Methods Propensity Score Bootstrap Shiny Leaflet\n\n\n\nIntégration full-stack pour l’exploration et interrogation sémantique des documents institutionnels. Architecture complète incluant preprocessing NLP (tokenisation, lemmatisation, NER), modèles d’embeddings (SBERT, Word2Vec), indexation ElasticSearch et interface web Next.js. Développement d’API FastAPI pour requêtes en temps réel et migration vers nouveau système d’archivage interne.\nPython spaCy SBERT ElasticSearch RAG FastAPI Next.js NLP Embeddings\n\n\n\nAlgorithmes de machine learning sur données longitudinales du Casier judiciaire national. Analyse de survie et scoring de risque pour trajectoires criminelles. Traitement intensif d’identifiants, constitution de panels temporels et modélisation de récidive pour aide à la décision publique en environnement sécurisé haute confidentialité.\nR Machine Learning Survival Analysis Panel Data Risk Scoring CASD Longitudinal Data\n\n\n\nExploitation d’enquêtes emploi INSEE et bases fiscales via CASD pour évaluation des réformes (retraites, loi PACTE). Modélisation statistique sur données administratives couplées, harmonisation de bases hétérogènes et appariement d’identifiants. Production d’indicateurs économiques et évaluation d’impact des politiques sociales.\nR Statistical Modeling Administrative Data Policy Evaluation Data Linkage CASD Economic Indicators\n\n\n\n\n\n\nConception d’outils pédagogiques : module de sondage statistique (stratification, pondération, calibration), tutoriel cartographie interactive (R/Python, Leaflet/Folium), template Quarto standardisé pour rapports reproductibles. Animation d’ateliers internes et documentation technique pour montée en compétences collective.\nR Python Quarto Pedagogy Documentation\n\n\n\nArchitecture de partage de connaissances : développement d’une plateforme interne de centralisation des ressources, peer reviews et sessions de formation. Mise en place de bonnes pratiques Git, standards de code et processus de validation collaborative.\nGitLab Collaboration Knowledge Management\n\n\n\n\n\n\n\n\n Formation sélective et intensive structurée autour de projets pluriannuels. Enseignements renforcés en économétrie, data science et analyse de politiques publiques. Réalisation de deux mémoires de recherche sous encadrement de Patrice Bertail, combinant modélisation avancée et valorisation scientifique. Approche projet avec autonomie dans l’identification de sources de données et mise en situation réelle. \n\n\nModélisation supervisée sur données déséquilibrées. Application de techniques SMOTE/B-SMOTE, validation croisée et scoring de risque financier. Comparaison de modèles (Random Forest, XGBoost, SVM) avec optimisation des métriques pour classes minoritaires.\nPython Scikit-learn SMOTE Cross-validation Financial Risk\n\n\n\nScraping haute fréquence vers datalake, classification et estimation des ajustements de prix par modèles d’effets fixes. Tests de robustesse et détection de patterns de tarification automatisée sur données e-commerce.\nPython Web Scraping Fixed Effects Price Analytics Data Lake\n\n\n\nModélisation économétrique cross-country (logit/Poisson) sur données d’enquête. Tests de robustesse par régularisation Lasso et analyse comparative des facteurs d’innovation (Inde, Bangladesh, Pakistan, Nepal).\nR Econometrics Cross-country Analysis Lasso Regularization Innovation Policy\n\n\n\nScraping de données gouvernementales ouvertes, construction de matrices de distance Manhattan et clustering spring layout pour identifier les coalitions transpartisanes. Visualisation interactive des proximités politiques.\nPython NetworkX Graph Theory Political Analysis Dash\n\n\n\nEntrepôt en étoile MySQL, requêtes à fenêtrage (moyennes mobiles) et tableau de bord territorial pour indicateurs de politique du logement. Architecture BI complète avec ETL via MageAI.\nSQL MySQL Power BI Data Warehouse ETL\n\n\n\nCartographie concurrentielle et positionnement stratégique sectoriel avec visualisations géospatiales. Analyse des familles de brevets, citations et recommandations de politique industrielle sur base officielle.\nPython SQL PATSTAT Patent Analysis Geospatial Viz\n\n\n\nPipeline de collecte et analyse : scraping de données massives, orchestration Airflow, ingestion temps réel dans datalake. Architecture Kafka/Spark avec stockage Parquet et monitoring Grafana.\nPython Airflow Kafka Spark Data Lake\n\n\n\nConstruction de graphe biparti acteurs-films, calcul de plus courts chemins avec NetworkX. Interface Dash pour requêtes interactives avec contraintes temporelles et visualisation de réseaux.\nPython NetworkX Graph Algorithms Dash Interactive Viz\n\n\n\n\n\n\n\n\nSensibilisation de lycéennes aux carrières scientifiques dans le cadre du plan national de promotion des filières STEM. Intervention auprès de l’Université Paris Nanterre pour déconstruction des stéréotypes de genre en mathématiques et sciences.\n\n\n\nDéveloppement de ressources pédagogiques : templates Quarto, modules R pour méthodes de sondage, tutoriels de cartographie interactive. Partage de bonnes pratiques en reproductibilité et documentation technique.\n\n\n\nArts numériques, design graphique, modélisation 3D, VTT, gymnastique, histoire contemporaine, numismatique"
  },
  {
    "objectID": "index.fr.html#cour-des-comptes-data-science-engineer-2023-aujourdhui",
    "href": "index.fr.html#cour-des-comptes-data-science-engineer-2023-aujourdhui",
    "title": "",
    "section": "",
    "text": "Intervention sur des projets d’évaluation de politiques publiques au sein de juridictions financières. Production d’analyses orientées décision en collaboration directe avec magistrats et parties prenantes institutionnelles. Maîtrise des standards de confidentialité et restitution claire dans des contextes formels. \n\n\nHarmonisation de données SIG hétérogènes France-Suisse pour identifier les discontinuités réglementaires transfrontalières. Recherche et exploitation de bases officielles (IGN, SwissTopo, SITG), couplage de nomenclatures et harmonisation d’échelles territoriales. Transformation d’analyses géospatiales complexes en visualisations interactives et recommandations de politique publique pour équipes institutionnelles.\nPython QGIS GeoPandas PlotLy\n\n\n\nModélisation économétrique avancée sur données nationales (GART, CEREMA) combinant panel models, event studies et méthodes de sondage. Traitement de bases confidentielles d’usagers par échantillonnage stratifié, redressement par score de propension, calage sur marges et bootstrapping. Enrichissement par recherche complémentaire (base FILOSOFI) pour formuler des recommandations tarifaires avec restitution interactive via Shiny.\nR Panel Data Event Study Causal Inference Survey Methods Propensity Score Bootstrap Shiny Leaflet\n\n\n\nIntégration full-stack pour l’exploration et interrogation sémantique des documents institutionnels. Architecture complète incluant preprocessing NLP (tokenisation, lemmatisation, NER), modèles d’embeddings (SBERT, Word2Vec), indexation ElasticSearch et interface web Next.js. Développement d’API FastAPI pour requêtes en temps réel et migration vers nouveau système d’archivage interne.\nPython spaCy SBERT ElasticSearch RAG FastAPI Next.js NLP Embeddings\n\n\n\nAlgorithmes de machine learning sur données longitudinales du Casier judiciaire national. Analyse de survie et scoring de risque pour trajectoires criminelles. Traitement intensif d’identifiants, constitution de panels temporels et modélisation de récidive pour aide à la décision publique en environnement sécurisé haute confidentialité.\nR Machine Learning Survival Analysis Panel Data Risk Scoring CASD Longitudinal Data\n\n\n\nExploitation d’enquêtes emploi INSEE et bases fiscales via CASD pour évaluation des réformes (retraites, loi PACTE). Modélisation statistique sur données administratives couplées, harmonisation de bases hétérogènes et appariement d’identifiants. Production d’indicateurs économiques et évaluation d’impact des politiques sociales.\nR Statistical Modeling Administrative Data Policy Evaluation Data Linkage CASD Economic Indicators"
  },
  {
    "objectID": "index.fr.html#projets-transversaux-et-contributions-institutionnelles",
    "href": "index.fr.html#projets-transversaux-et-contributions-institutionnelles",
    "title": "",
    "section": "",
    "text": "Conception d’outils pédagogiques : module de sondage statistique (stratification, pondération, calibration), tutoriel cartographie interactive (R/Python, Leaflet/Folium), template Quarto standardisé pour rapports reproductibles. Animation d’ateliers internes et documentation technique pour montée en compétences collective.\nR Python Quarto Pedagogy Documentation\n\n\n\nArchitecture de partage de connaissances : développement d’une plateforme interne de centralisation des ressources, peer reviews et sessions de formation. Mise en place de bonnes pratiques Git, standards de code et processus de validation collaborative.\nGitLab Collaboration Knowledge Management"
  },
  {
    "objectID": "index.fr.html#cursus-master-ingénierie-data-science-for-social-sciences-université-paris-nanterre-2020-2025",
    "href": "index.fr.html#cursus-master-ingénierie-data-science-for-social-sciences-université-paris-nanterre-2020-2025",
    "title": "",
    "section": "",
    "text": "Formation sélective et intensive structurée autour de projets pluriannuels. Enseignements renforcés en économétrie, data science et analyse de politiques publiques. Réalisation de deux mémoires de recherche sous encadrement de Patrice Bertail, combinant modélisation avancée et valorisation scientifique. Approche projet avec autonomie dans l’identification de sources de données et mise en situation réelle. \n\n\nModélisation supervisée sur données déséquilibrées. Application de techniques SMOTE/B-SMOTE, validation croisée et scoring de risque financier. Comparaison de modèles (Random Forest, XGBoost, SVM) avec optimisation des métriques pour classes minoritaires.\nPython Scikit-learn SMOTE Cross-validation Financial Risk\n\n\n\nScraping haute fréquence vers datalake, classification et estimation des ajustements de prix par modèles d’effets fixes. Tests de robustesse et détection de patterns de tarification automatisée sur données e-commerce.\nPython Web Scraping Fixed Effects Price Analytics Data Lake\n\n\n\nModélisation économétrique cross-country (logit/Poisson) sur données d’enquête. Tests de robustesse par régularisation Lasso et analyse comparative des facteurs d’innovation (Inde, Bangladesh, Pakistan, Nepal).\nR Econometrics Cross-country Analysis Lasso Regularization Innovation Policy\n\n\n\nScraping de données gouvernementales ouvertes, construction de matrices de distance Manhattan et clustering spring layout pour identifier les coalitions transpartisanes. Visualisation interactive des proximités politiques.\nPython NetworkX Graph Theory Political Analysis Dash\n\n\n\nEntrepôt en étoile MySQL, requêtes à fenêtrage (moyennes mobiles) et tableau de bord territorial pour indicateurs de politique du logement. Architecture BI complète avec ETL via MageAI.\nSQL MySQL Power BI Data Warehouse ETL\n\n\n\nCartographie concurrentielle et positionnement stratégique sectoriel avec visualisations géospatiales. Analyse des familles de brevets, citations et recommandations de politique industrielle sur base officielle.\nPython SQL PATSTAT Patent Analysis Geospatial Viz\n\n\n\nPipeline de collecte et analyse : scraping de données massives, orchestration Airflow, ingestion temps réel dans datalake. Architecture Kafka/Spark avec stockage Parquet et monitoring Grafana.\nPython Airflow Kafka Spark Data Lake\n\n\n\nConstruction de graphe biparti acteurs-films, calcul de plus courts chemins avec NetworkX. Interface Dash pour requêtes interactives avec contraintes temporelles et visualisation de réseaux.\nPython NetworkX Graph Algorithms Dash Interactive Viz"
  }
]